 import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import davies_bouldin_score
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity

 
customers = pd.read_csv("Customers.csv")
products = pd.read_csv("Products.csv")
transactions = pd.read_csv("Transactions.csv")

 
print("Customers Dataset:\n", customers.info())
print("Products Dataset:\n", products.info())
print("Transactions Dataset:\n", transactions.info())

 
sns.countplot(y='Region', data=customers)
plt.title("Customer Distribution by Region")
plt.show()

 
data = pd.merge(transactions, customers, on='CustomerID', how='left')
data = pd.merge(data, products, on='ProductID', how='left')

 
interaction_matrix = data.pivot_table(index='CustomerID', columns='ProductID', values='Quantity', fill_value=0)

 
similarity = cosine_similarity(interaction_matrix)
similarity_df = pd.DataFrame(similarity, index=interaction_matrix.index, columns=interaction_matrix.index)

 
def get_top_lookalikes(customer_id, top_n=3):
    if customer_id not in similarity_df.columns:
        print(f"Customer ID {customer_id} not found in similarity matrix.")
        return pd.Series()
     
    scores = similarity_df[customer_id].sort_values(ascending=False)
     
    top_scores = scores.iloc[1:top_n+1]
    return top_scores

 
lookalikes = {}
for customer in customers['CustomerID'][:20]:
    top_customers = get_top_lookalikes(customer)
    lookalikes[customer] = list(zip(top_customers.index, top_customers.values))

 
lookalike_df = pd.DataFrame.from_dict(lookalikes, orient='index', columns=['Lookalike1', 'Lookalike2', 'Lookalike3'])
lookalike_df.to_csv("Lookalike.csv", index_label="CustomerID")

customer_data = customers.merge(transactions.groupby('CustomerID').sum(numeric_only=True), on='CustomerID')
scaler = StandardScaler()
scaled_data = scaler.fit_transform(customer_data.select_dtypes(include=np.number))

 
kmeans = KMeans(n_clusters=4, random_state=42)
clusters = kmeans.fit_predict(scaled_data)
customer_data['Cluster'] = clusters

 
db_index = davies_bouldin_score(scaled_data, clusters)
print(f"Davies-Bouldin Index: {db_index}")

 
sns.scatterplot(x=scaled_data[:, 0], y=scaled_data[:, 1], hue=clusters, palette='viridis')
plt.title("Customer Segmentation Clusters")
plt.show()

 
customer_data.to_csv("Clustering_Results.csv", index=False)

 
print("\n-- EDA Insights --")
print("Total Customers:", customers.shape[0])
print("Total Products:", products.shape[0])
print("Total Transactions:", transactions.shape[0])

print("\nTop 5 Customers by Total Purchase Value:")
top_customers = transactions.groupby('CustomerID')['TotalValue'].sum().sort_values(ascending=False).head()
print(top_customers)

print("\nTop 5 Most Popular Products:")
popular_products = transactions.groupby('ProductID')['Quantity'].sum().sort_values(ascending=False).head()
print(popular_products)

print("\nClusters Summary:")
print(customer_data.groupby('Cluster').mean(numeric_only=True))

# Final Notes
print("EDA, Lookalike Model, and Clustering tasks are completed. Results have been saved.")
